# CreditScore â€” Machine Learning Credit Risk Model

This repository contains a complete **end-to-end machine learning pipeline** for predicting customer credit scores using real-world financial data.  
The project includes **data preprocessing**, **hyperparameter optimization** with Optuna, **model training** using XGBoost, **MLflow experiment tracking**, and result visualization.

---

## Project Overview

The goal of this project is to build a **credit scoring model** that predicts a customerâ€™s creditworthiness based on their historical financial and behavioral profile.

The pipeline:
1. **Preprocessing & Feature Engineering** â€” cleaning, encoding, and transforming raw data.  
2. **Hyperparameter Optimization** â€” tuning XGBoost with **Optuna** and 5-fold CV.  
3. **Model Training & Evaluation** â€” final model trained with the best parameters.  
4. **Experiment Tracking** â€” all metrics logged in **MLflow**.  
5. **Visualization** â€” insights into model performance and feature importance.

---

## Project Structure

CreditScore/
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ preprocessing.ipynb          # Data cleaning & preparation
â”‚   â”œâ”€â”€ params_optuna.py             # Hyperparameter optimization with Optuna
â”‚   â”œâ”€â”€ train_xgb_model.py           # Model training + MLflow logging
â”‚   â””â”€â”€ visualizations.ipynb         # Feature importance & confusion matrix
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â”œâ”€â”€ train_preprocessed.csv
â”‚   â”œâ”€â”€ test_preprocessed.csv
â”‚   â”œâ”€â”€ optuna_xgb_study.pkl
â”‚   â””â”€â”€ XGBoost75Accuracy.pkl
â”‚
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ confusion_matrix.png
â”‚
â”œâ”€â”€ mlruns/                          # Auto-generated by MLflow
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

##  Model Details

| Component | Description |
|------------|-------------|
| **Algorithm** | XGBoost (multi-class classification) |
| **Objective** | `multi:softprob` |
| **Optimization** | Optuna (5-fold CV, Median Pruner) |
| **Evaluation Metrics** | Accuracy, F1, Precision, Recall |
| **Tracking** | MLflow experiment logging |
| **Feature Importance** | Gain-based ranking (Top 15 features) |

---

## ðŸ“Š Results

| Metric | Score |
|:-------|:------|
| **Accuracy** | 0.75 |
| **Weighted F1-score** | ~0.75 |
| **ROC AUC (multi-class)** | 0.78 |

### ðŸ”¹ Top 15 Most Important Features
<p align="center">
  <img src="plots/feature_importance.png" width="80%">
</p>

### ðŸ”¹ Normalized Confusion Matrix
<p align="center">
  <img src="plots/confusion_matrix.png" width="55%">
</p>

---

## Tools & Technologies

- **Python 3.11**
- **XGBoost** â€” gradient boosting algorithm  
- **Optuna** â€” hyperparameter tuning  
- **scikit-learn** â€” model evaluation & metrics  
- **MLflow** â€” experiment tracking and model versioning  
- **Matplotlib / Seaborn** â€” result visualization  
- **Pandas / NumPy** â€” data handling & preprocessing  

---

## Future Improvements

- Add SHAP explainability to interpret model predictions  
- Build REST API with FastAPI for real-time inference  
- Deploy the model using Docker or Streamlit Cloud  
- Extend MLflow tracking to cloud backend (e.g. DagsHub / AWS S3)

---

## Author

**BartÅ‚omiej PÄ™k**  
*Machine Learning Engineer / Data Scientist*  
ðŸ“§ [bartekpek123@gmail.com](mailto:bartekpek123@gmail.com)  
ðŸ”— [linkedin.com/in/bartlomiejpek](https://www.linkedin.com/in/bartlomiejpek)

---
